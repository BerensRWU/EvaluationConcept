{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import config.astyx_config as cnf\n",
    "from models.model_utils import create_model\n",
    "from evaluate import evaluate_mAP\n",
    "\n",
    "sys.path.append('/media/berens/T7/Dissertation/ComplexYOLO/Astyx/src/')\n",
    "\n",
    "from data_process_astyx.astyx_dataloader import create_val_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/media/berens/T7/Dissertation/ComplexYOLO/Astyx/src/checkpoints/\"\n",
    "\n",
    "c = plt.colormaps()\n",
    "colors = plt.cm.jet(np.linspace(0, 1, 6))\n",
    "\n",
    "configs = edict({\"arch\": \"darknet\",\n",
    "                 \"cfgfile\": \"./config/cfg/complex_yolov4.cfg\",\n",
    "                 \"use_giou_loss\": False,\n",
    "                 \"device\": \"cpu\",\n",
    "                 \"dataset_dir\": f\"{root}/../../dataset_astyx_hires2019\",\n",
    "                 \"num_samples\": 100,\n",
    "                 \"dist_prop_lidar\": 1,\n",
    "                 \"dist_prop_radar\": 1,\n",
    "                 \"disturb_types_training_lidar\" : [None],\n",
    "                 \"disturb_levels_training_lidar\": [0],\n",
    "                 \"disturb_types_training_radar\" : [None],\n",
    "                 \"disturb_levels_training_radar\": [0],\n",
    "                 \"set_seed\": 1000,\n",
    "                 \"distributed\": False,\n",
    "                 \"batch_size\": 1,\n",
    "                 \"pin_memory\": True,\n",
    "                 \"num_workers\": 1,\n",
    "                 \"img_size\": 608,\n",
    "                 \"conf_thresh\": 0.5,\n",
    "                 \"nms_thresh\": 0.5,\n",
    "                 \"iou_thresh\": 0.5,\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_config(configs, lidar_disturb, radar_disturb, seed):\n",
    "    \"\"\"\n",
    "    Creates a new configuration based on the original configuration.\n",
    "    \n",
    "    Parameters:\n",
    "    - configs: edict\n",
    "        The original configuration to be copied.\n",
    "    - lidar_disturb: str or None\n",
    "        The type of disturbance for the LiDAR sensor.\n",
    "    - radar_disturb: str or None\n",
    "        The type of disturbance for the RADAR sensor.\n",
    "    - seed: int\n",
    "        The random seed to be used for the new configuration.\n",
    "    \n",
    "    Returns:\n",
    "    - config_copy: edict\n",
    "        The created configuration with specified disturbance types and the set seed.\n",
    "    \"\"\"\n",
    "    config_copy = edict(configs.copy())\n",
    "    config_copy.disturb_types_training_lidar = [lidar_disturb] if lidar_disturb else ['None']\n",
    "    config_copy.disturb_types_training_radar = [radar_disturb] if radar_disturb else ['None']\n",
    "    config_copy.set_seed = seed\n",
    "    config_copy.subdivisions = int(64 / config_copy.batch_size)\n",
    "    return config_copy\n",
    "\n",
    "def evaluate_disturbance(config, level, model):\n",
    "    \"\"\"\n",
    "    Evaluates the model's performance under the specified disturbance conditions.\n",
    "    \n",
    "    Parameters:\n",
    "    - config: edict\n",
    "        The configuration containing the current disturbance conditions.\n",
    "    - level: float\n",
    "        The level of disturbance to be applied during evaluation.\n",
    "    - model: Model\n",
    "        The model being evaluated.\n",
    "    \n",
    "    Returns:\n",
    "    - precision[0]: float\n",
    "        The precision of the model on the first class.\n",
    "    - recall[0]: float\n",
    "        The recall of the model on the first class.\n",
    "    - AP[0]: float\n",
    "        The average precision (AP) of the model on the first class.\n",
    "    - f1[0]: float\n",
    "        The F1 score of the model on the first class.\n",
    "    \"\"\"\n",
    "    if config.disturb_types_training_lidar != ['None']:\n",
    "        config.disturb_levels_training_lidar = [level]\n",
    "    if config.disturb_types_training_radar != ['None']:\n",
    "        config.disturb_levels_training_radar = [level]\n",
    "    val_dataloader = create_val_dataloader(config)\n",
    "    precision, recall, AP, f1, ap_class = evaluate_mAP(val_dataloader, model, config, None)\n",
    "    return precision[0], recall[0], AP[0], f1[0]\n",
    "\n",
    "def run_evaluations(config, model, levels):\n",
    "    \"\"\"\n",
    "    Iterates through different disturbance levels and evaluates model performance for each.\n",
    "    \n",
    "    Parameters:\n",
    "    - config: edict\n",
    "        The configuration containing the current disturbance conditions.\n",
    "    - model: Model\n",
    "        The model being evaluated.\n",
    "    - levels: list of floats\n",
    "        The different levels of disturbance to be tested.\n",
    "    \n",
    "    Returns:\n",
    "    - eval_values: np.ndarray\n",
    "        An array of evaluation results across the different disturbance levels.\n",
    "    \"\"\"\n",
    "    eval_values = np.zeros(len(levels))\n",
    "    for level_id, level in enumerate(levels):\n",
    "        eval_values[level_id] = evaluate_disturbance(config, level, model)\n",
    "    return eval_values\n",
    "\n",
    "def make_plot(eval_data, subplot, xticks = np.arange(0,1.1,0.1), title):\n",
    "    \"\"\"\n",
    "    Plots evaluation data on the provided subplot with markers and colors corresponding to different levels of disturbance.\n",
    "\n",
    "    Parameters:\n",
    "    - eval_data: np.ndarray\n",
    "        The evaluation data to plot, with rows corresponding to different proportions and columns to different disturbance levels.\n",
    "    - subplot: matplotlib.axes.Axes\n",
    "        The subplot on which the data will be plotted.\n",
    "    - xticks: np.ndarray, optional\n",
    "        The values to be used for the x-axis ticks, default is np.arange(0, 1.1, 0.1).\n",
    "    - title: str, optional\n",
    "        The title of the subplot, default is an empty string.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for eval_level in range(data_disturbed.shape[1]):\n",
    "        subplot.plot(xticks,data_disturbed[:,eval_level],marker=\".\",markersize=10,c=colors[eval_level])\n",
    "\n",
    "    subplot.plot(xticks,data_disturbed.mean(1),marker=\".\",markersize=10,c=[0.5, 0.5 , 0.5])\n",
    "        \n",
    "    subplot.set_xlabel(\"Proportion of introduced distortions\",fontsize=\"x-large\")\n",
    "    subplot.set_ylim((0,1))\n",
    "    subplot.set_ylabel(performanzmass,fontsize=\"x-large\")\n",
    "    subplot.set_xticks(np.arange(0,1.1,0.1))\n",
    "    subplot.legend([plt.Line2D([], [], linestyle='-', marker='o', color=colors[0]),\n",
    "                   plt.Line2D([], [], linestyle='-', marker='o', color=colors[1]),\n",
    "                   plt.Line2D([], [], linestyle='-', marker='o', color=colors[2]),\n",
    "                   plt.Line2D([], [], linestyle='-', marker='o', color=colors[3]),\n",
    "                   plt.Line2D([], [], linestyle='-', marker='o', color=colors[4]),\n",
    "                   plt.Line2D([], [], linestyle='-', marker='o', color=[0.5, 0.5 , 0.5 ])],\n",
    "                   [0,1,2,3,4, \"Mean\"], title=\"Diff. Eval.\",fontsize=\"x-large\", title_fontsize=\"x-large\")\n",
    "    \n",
    "    subplot.set_title(title,fontsize=\"x-large\")\n",
    "            \n",
    "def multifactorial_performance(configs, pretrained_path_list, proportions, disturbances, levels, title_lidar, title_radar, title_both):\n",
    "    \"\"\"\n",
    "    Evaluates model performance across multiple pretrained models, disturbances, and levels, and generates plots for each sensor type.\n",
    "\n",
    "    Parameters:\n",
    "    - configs: edict\n",
    "        The configuration object containing settings for the model and evaluation.\n",
    "    - pretrained_path_list: list of str\n",
    "        List of file paths to the pretrained model checkpoints.\n",
    "    - proportions: list of float\n",
    "        List of proportions for introduced distortions, used for x-axis in the plot.\n",
    "    - disturbances: list of str\n",
    "        List of disturbance types to evaluate.\n",
    "    - levels: list of float\n",
    "        List of levels of disturbances.\n",
    "    - title_lidar: str\n",
    "        Title for the LiDAR evaluation plot.\n",
    "    - title_radar: str\n",
    "        Title for the RADAR evaluation plot.\n",
    "    - title_both: str\n",
    "        Title for the combined LiDAR and RADAR evaluation plot.\n",
    "\n",
    "    Returns:\n",
    "    - fig: matplotlib.figure.Figure\n",
    "        The created Matplotlib figure with the results.\n",
    "    - ax: numpy.ndarray of matplotlib.axes.Axes\n",
    "        The axes of the subplots in the figure.\n",
    "    - eval_values_lidar: np.ndarray\n",
    "        The evaluation results for LiDAR disturbances.\n",
    "    - eval_values_radar: np.ndarray\n",
    "        The evaluation results for RADAR disturbances.\n",
    "    - eval_values_both: np.ndarray\n",
    "        The evaluation results for disturbances on both sensors.\n",
    "    \"\"\"\n",
    "    seed = np.random.randint(10000)\n",
    "    \n",
    "    if configs.disturb_types_training_lidar != [None] and configs.disturb_types_training_radar != [None]:\n",
    "        Sensor_T = \"both\"\n",
    "    elif configs.disturb_types_training_lidar != [None]:\n",
    "        Sensor_T = \"LiDAR\"\n",
    "    elif configs.disturb_types_training_radar != [None]:\n",
    "        Sensor_T = \"RADAR\"\n",
    "    \n",
    "    Type_T = configs.disturb_types_training_lidar\n",
    "    \n",
    "    eval_values_lidar = np.zeros(len(pretrained_path_list), len(disturbances), len(levels))\n",
    "    eval_values_radar = np.zeros(len(pretrained_path_list), len(disturbances), len(levels))\n",
    "    eval_values_both = np.zeros(len(pretrained_path_list), len(disturbances), len(levels))\n",
    "    \n",
    "    for pretrained_path_idx, pretrained_path in enumerate(pretrained_path_list):\n",
    "        model = create_model(configs)\n",
    "        model.load_state_dict(torch.load(pretrained_path,\n",
    "                                         map_location=torch.device(configs.device)))\n",
    "        model = model.to(device=configs.device)\n",
    "        model = model.eval()\n",
    "        \n",
    "        for disturb_id, disturb in enumerate(disturbances):\n",
    "            lidar_config = create_config(configs, disturb, None, seed)\n",
    "            radar_config = create_config(configs, None, disturb, seed)\n",
    "            both_config = create_config(configs, disturb, disturb, seed)\n",
    "\n",
    "            eval_values_lidar[pretrained_path_idx, disturb_id] = run_evaluations(lidar_config, model)\n",
    "            eval_values_radar[pretrained_path_idx, disturb_id] = run_evaluations(radar_config, model)\n",
    "            eval_values_both[pretrained_path_idx, disturb_id] = run_evaluations(both_config, model)\n",
    "\n",
    "    eval_values_lidar = eval_values_lidar.mean(axis = 1)\n",
    "    eval_values_radar = eval_values_radar.mean(axis = 1)\n",
    "    eval_values_both = eval_values_both.mean(axis = 1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3,frameon=False)\n",
    "    make_plot(eval_values_lidar, subplot = ax, xticks = proportions,\n",
    "                 title_lidar)\n",
    "    make_plot(eval_values_radar, subplot = ax, xticks = proportions,\n",
    "                 title_radar)\n",
    "    make_plot(eval_values_both, subplot = ax, xticks = proportions,\n",
    "                 title_both)\n",
    "    return fig, ax, eval_values_lidar, eval_values_radar, eval_values_both\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Level Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.low_fusion = True\n",
    "configs.high_fusion = False\n",
    "configs.lidar = False\n",
    "configs.radar = False\n",
    "configs.VR = False\n",
    "\n",
    "disturbances = ['random_noise', 'random_loss', 'random_shift', 'blobs', 'intensity']\n",
    "levels = [[0.], [0.25], [0.5], [0.75], [1.]]\n",
    "\n",
    "pretrained_path_list = [\"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_0.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_1.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_2.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_3.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_4.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_5.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_6.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_7.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_8.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_0_9.pht\",\n",
    "                       \"./models/complexyolov4_astyx_lidar/random_noise_4/Model_1_0.pht\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multifactorial_performance(configs, pretrained_path_list,\n",
    "                           proportions, disturbances[0], levels,\n",
    "                           title_lidar = \"Complex-YOLO Low Level Training: Level = 4,\\n Sensor = both, Disturbance = Random Noise \\\n",
    "\\n Eval.: Sensor = LiDAR, Disturbance = Random Noise\",\n",
    "                           title_radar = \"Complex-YOLO Low Level Training: Level = 4,\\n Sensor = both, Disturbance = Random Noise \\\n",
    "\\n Eval.: Sensor = RADAR, Disturbance = Random Noise\",\n",
    "                           title_both = \"Complex-YOLO Low Level Training: Level = 4,\\n Sensor = both, Disturbance = Random Noise \\\n",
    "\\n Eval.: Sensor = both, Disturbance = Random Noise\"):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcpu",
   "language": "python",
   "name": "torchcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
