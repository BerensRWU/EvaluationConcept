{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import config.astyx_config as cnf\n",
    "from models.model_utils import create_model\n",
    "from evaluate import evaluate_mAP\n",
    "\n",
    "sys.path.append('./')\n",
    "\n",
    "from data_process_astyx.astyx_dataloader import create_val_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = #### your Path\n",
    "\n",
    "configs = edict({\"arch\": \"darknet\",\n",
    "                 \"cfgfile\": \"./config/cfg/complex_yolov4.cfg\",\n",
    "                 \"use_giou_loss\": False,\n",
    "                 \"device\": \"cpu\",\n",
    "                 \"dataset_dir\": f\"{root}/path/to/data\",\n",
    "                 \"num_samples\": 100,\n",
    "                 \"dist_prop_lidar\": 1,\n",
    "                 \"dist_prop_radar\": 1,\n",
    "                 \"disturb_types_training_lidar\" : [None],\n",
    "                 \"disturb_levels_training_lidar\": [0],\n",
    "                 \"disturb_types_training_radar\" : [None],\n",
    "                 \"disturb_levels_training_radar\": [0],\n",
    "                 \"set_seed\": 1000,\n",
    "                 \"distributed\": False,\n",
    "                 \"batch_size\": 1,\n",
    "                 \"pin_memory\": True,\n",
    "                 \"num_workers\": 1,\n",
    "                 \"img_size\": 608,\n",
    "                 \"conf_thresh\": 0.5,\n",
    "                 \"nms_thresh\": 0.5,\n",
    "                 \"iou_thresh\": 0.5,\n",
    "                 \"pretrained_path\": f\"{root}/path/to/model\"\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_config(configs, lidar_disturb, radar_disturb, seed):\n",
    "    \"\"\"\n",
    "    Creates a new configuration based on the original configuration.\n",
    "    \n",
    "    Parameters:\n",
    "    - configs: edict\n",
    "        The original configuration to be copied.\n",
    "    - lidar_disturb: str or None\n",
    "        The type of disturbance for the LiDAR sensor.\n",
    "    - radar_disturb: str or None\n",
    "        The type of disturbance for the RADAR sensor.\n",
    "    - seed: int\n",
    "        The random seed to be used for the new configuration.\n",
    "    \n",
    "    Returns:\n",
    "    - config_copy: edict\n",
    "        The created configuration with specified disturbance types and the set seed.\n",
    "    \"\"\"\n",
    "    config_copy = edict(configs.copy())\n",
    "    config_copy.disturb_types_training_lidar = [lidar_disturb] if lidar_disturb else ['None']\n",
    "    config_copy.disturb_types_training_radar = [radar_disturb] if radar_disturb else ['None']\n",
    "    config_copy.set_seed = seed\n",
    "    config_copy.subdivisions = int(64 / config_copy.batch_size)\n",
    "    return config_copy\n",
    "\n",
    "def evaluate_disturbance(config, level, model):\n",
    "    \"\"\"\n",
    "    Evaluates the model's performance under the specified disturbance conditions.\n",
    "    \n",
    "    Parameters:\n",
    "    - config: edict\n",
    "        The configuration containing the current disturbance conditions.\n",
    "    - level: float\n",
    "        The level of disturbance to be applied during evaluation.\n",
    "    - model: Model\n",
    "        The model being evaluated.\n",
    "    \n",
    "    Returns:\n",
    "    - precision[0]: float\n",
    "        The precision of the model on the first class.\n",
    "    - recall[0]: float\n",
    "        The recall of the model on the first class.\n",
    "    - AP[0]: float\n",
    "        The average precision (AP) of the model on the first class.\n",
    "    - f1[0]: float\n",
    "        The F1 score of the model on the first class.\n",
    "    \"\"\"\n",
    "    if config.disturb_types_training_lidar != ['None']:\n",
    "        config.disturb_levels_training_lidar = [level]\n",
    "    if config.disturb_types_training_radar != ['None']:\n",
    "        config.disturb_levels_training_radar = [level]\n",
    "    val_dataloader = create_val_dataloader(config)\n",
    "    precision, recall, AP, f1, ap_class = evaluate_mAP(val_dataloader, model, config, None)\n",
    "    return precision[0], recall[0], AP[0], f1[0]\n",
    "\n",
    "def run_evaluations(config, model, levels):\n",
    "    \"\"\"\n",
    "    Iterates through different disturbance levels and evaluates model performance for each.\n",
    "    \n",
    "    Parameters:\n",
    "    - config: edict\n",
    "        The configuration containing the current disturbance conditions.\n",
    "    - model: Model\n",
    "        The model being evaluated.\n",
    "    - levels: list of floats\n",
    "        The different levels of disturbance to be tested.\n",
    "    \n",
    "    Returns:\n",
    "    - eval_values: np.ndarray\n",
    "        An array of evaluation results across the different disturbance levels.\n",
    "    \"\"\"\n",
    "    eval_values = np.zeros(len(levels))\n",
    "    for level_id, level in enumerate(levels):\n",
    "        eval_values[level_id] = evaluate_disturbance(config, level, model)\n",
    "    return eval_values\n",
    "\n",
    "def plot_single(ax, data, title, disturbance_types, levels):\n",
    "    \"\"\"\n",
    "    Creates a single subplot visualizing the model evaluation results.\n",
    "    \n",
    "    Parameters:\n",
    "    - ax: matplotlib.axes.Axes\n",
    "        The axis on which the subplot will be drawn.\n",
    "    - data: np.ndarray\n",
    "        The data to be plotted.\n",
    "    - title: str\n",
    "        The title of the subplot.\n",
    "    - disturbance_types: list of str\n",
    "        The types of disturbances to be displayed on the y-axis.\n",
    "    - levels: list of int\n",
    "        The levels of disturbances to be displayed on the x-axis.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    ax.set_yticks(range(len(disturbance_types)), disturbance_types)\n",
    "    ax.set_xticks(range(len(levels)), levels)\n",
    "    cbar = plt.colorbar(ax.imshow(data[:, 1:], vmin=0, vmax=1), ax=ax, orientation='horizontal', location='bottom')\n",
    "    cbar.set_label(f'AP')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Level\")\n",
    "    ax.set_ylabel(\"Type of distortion\")\n",
    "\n",
    "def plot_results(eval_values_lidar, eval_values_radar, eval_values_both, disturbance_types, levels=[1, 2, 3, 4]):\n",
    "    \"\"\"\n",
    "    Creates the overall plot with the model evaluations under various disturbance conditions.\n",
    "    \n",
    "    Parameters:\n",
    "    - eval_values_lidar: np.ndarray\n",
    "        The evaluation results for disturbances on the LiDAR sensor.\n",
    "    - eval_values_radar: np.ndarray\n",
    "        The evaluation results for disturbances on the RADAR sensor.\n",
    "    - eval_values_both: np.ndarray\n",
    "        The evaluation results for disturbances on both sensors.\n",
    "    - disturbance_types: list of str\n",
    "        The types of disturbances to be displayed on the y-axes.\n",
    "    - levels: list of int, optional\n",
    "        The levels of disturbances to be displayed on the x-axes.\n",
    "    \n",
    "    Returns:\n",
    "    - fig: matplotlib.figure.Figure\n",
    "        The created Matplotlib figure.\n",
    "    - ax: numpy.ndarray of matplotlib.axes.Axes\n",
    "        The axes of the subplots in the figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(20, 20), frameon=False)\n",
    "\n",
    "    plot_single(ax[0, 0], eval_values_lidar, \"Evaluated with interference on the LiDAR sensor\", disturbance_types, levels)\n",
    "    plot_single(ax[0, 1], eval_values_radar, \"Evaluated with interference on the RADAR sensor\", disturbance_types, levels)\n",
    "    plot_single(ax[1, 1], eval_values_both, \"Evaluated with interference on both sensors\", disturbance_types, levels)\n",
    "    \n",
    "    ax[1, 0].axis(\"off\")\n",
    "    return fig, ax\n",
    "\n",
    "def sensitivity_analysis(configs, model, disturbances, levels):\n",
    "    \"\"\"\n",
    "    Performs a sensitivity analysis by evaluating the model on various disturbances and levels.\n",
    "    \n",
    "    Parameters:\n",
    "    - configs: edict\n",
    "        The original configuration from which copies will be made for the analysis.\n",
    "    - model: Model\n",
    "        The model being evaluated.\n",
    "    - disturbances: list of str\n",
    "        The types of disturbances to be investigated.\n",
    "    - levels: list of floats\n",
    "        The different levels of disturbance to be tested.\n",
    "    \n",
    "    Returns:\n",
    "    - fig: matplotlib.figure.Figure\n",
    "        The created Matplotlib figure with the results.\n",
    "    - ax: numpy.ndarray of matplotlib.axes.Axes\n",
    "        The axes of the subplots in the figure.\n",
    "    - eval_values_lidar: np.ndarray\n",
    "        The evaluation results for LiDAR disturbances.\n",
    "    - eval_values_radar: np.ndarray\n",
    "        The evaluation results for RADAR disturbances.\n",
    "    - eval_values_both: np.ndarray\n",
    "        The evaluation results for disturbances on both sensors.\n",
    "    \"\"\"\n",
    "    seed = np.random.randint(10000)\n",
    "    \n",
    "    eval_values_lidar = np.zeros((len(disturbances), len(levels)))\n",
    "    eval_values_radar = np.zeros((len(disturbances), len(levels)))\n",
    "    eval_values_both = np.zeros((len(disturbances), len(levels)))\n",
    "\n",
    "    for disturb_id, disturb in enumerate(disturbances):\n",
    "        lidar_config = create_config(configs, disturb, None, seed)\n",
    "        radar_config = create_config(configs, None, disturb, seed)\n",
    "        both_config = create_config(configs, disturb, disturb, seed)\n",
    "        \n",
    "        eval_values_lidar[disturb_id] = run_evaluations(lidar_config, model, levels)\n",
    "        eval_values_radar[disturb_id] = run_evaluations(radar_config, model, levels)\n",
    "        eval_values_both[disturb_id] = run_evaluations(both_config, model, levels)\n",
    "\n",
    "    fig, ax = plot_results(eval_values_lidar, eval_values_radar, eval_values_both, disturbances, levels)\n",
    "    \n",
    "    return fig, ax, eval_values_lidar, eval_values_radar, eval_values_both\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Level Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.low_fusion = True\n",
    "configs.high_fusion = False\n",
    "configs.lidar = False\n",
    "configs.radar = False\n",
    "configs.VR = False\n",
    "\n",
    "disturbances = ['random_noise', 'random_loss', 'random_shift', 'blobs', 'intensity']\n",
    "levels = [[0.], [0.25], [0.5], [0.75], [1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(configs)\n",
    "model.load_state_dict(torch.load(\n",
    "                                 configs.pretrained_path,\n",
    "                                 map_location=torch.device(configs.device)))\n",
    "model = model.to(device=configs.device)\n",
    "model = model.eval()\n",
    "\n",
    "sensitivity_analysis(configs, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcpu",
   "language": "python",
   "name": "torchcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
